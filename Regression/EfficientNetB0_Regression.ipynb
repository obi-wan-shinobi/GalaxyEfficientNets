{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gUEMrdn7Y3gc",
    "outputId": "6e00050c-3ad4-46ad-9629-fb996717964d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "C4ycYe3j55TT",
    "outputId": "581ee8c3-1ac8-4829-b132-92f216c156b4"
   },
   "outputs": [],
   "source": [
    "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "!pip install gputil\n",
    "!pip install psutil\n",
    "!pip install humanize\n",
    "import psutil\n",
    "import humanize\n",
    "import os\n",
    "import GPUtil as GPU\n",
    "GPUs = GPU.getGPUs()\n",
    "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
    "gpu = GPUs[0]\n",
    "def printm():\n",
    " process = psutil.Process(os.getpid())\n",
    " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "printm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "wuYZc7J4ZZp3",
    "outputId": "0d780cb5-4be7-4e35-cd43-9fa31e411024"
   },
   "outputs": [],
   "source": [
    "'''resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
    "tf.config.experimental_connect_to_cluster(resolver)\n",
    "# This is the TPU initialization code that has to be at the beginning.\n",
    "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "strategy = tf.distribute.experimental.TPUStrategy(resolver)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v2y11miyZb-j"
   },
   "outputs": [],
   "source": [
    "DIR = \"/content/training_solutions_rev1.csv\"\n",
    " \n",
    "train_path = \"/content/images_training_rev1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "6oTlPx0PaK3F",
    "outputId": "a4ac097a-2aa1-4299-ef10-cb551f91952e"
   },
   "outputs": [],
   "source": [
    "classes = [\n",
    "    'Class1.1', 'Class1.2', 'Class1.3', 'Class2.1', 'Class2.2', 'Class3.1',\n",
    "    'Class3.2', 'Class4.1', 'Class4.2', 'Class5.1', 'Class5.2', 'Class5.3',\n",
    "    'Class5.4', 'Class6.1', 'Class6.2', 'Class7.1', 'Class7.2', 'Class7.3',\n",
    "    'Class8.1', 'Class8.2', 'Class8.3', 'Class8.4', 'Class8.5', 'Class8.6',\n",
    "    'Class8.7', 'Class9.1', 'Class9.2', 'Class9.3', 'Class10.1', 'Class10.2',\n",
    "    'Class10.3', 'Class11.1', 'Class11.2', 'Class11.3', 'Class11.4',\n",
    "    'Class11.5', 'Class11.6'\n",
    "]\n",
    "\n",
    "\n",
    "def append_ext(fn):\n",
    "    return fn + \".jpg\"\n",
    "\n",
    "\n",
    "traindf = pd.read_csv(DIR)\n",
    "traindf[\"id\"] = traindf['GalaxyID'].astype(str).apply(append_ext)\n",
    "\n",
    "def random_input(img):\n",
    "    shape = img.shape[:2]\n",
    "    left = int(shape[0]/4)\n",
    "    top = int(shape[1]/4)\n",
    "    img = img[left:left*3,top:top*3,:]\n",
    "    image = cv2.resize(img, shape, interpolation = cv2.INTER_CUBIC)\n",
    "    image = img_to_array(image)\n",
    "    return image\n",
    "  \n",
    "datagen = ImageDataGenerator(\n",
    "    #featurewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    rescale=1. / 255,\n",
    "    rotation_range=90,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    brightness_range = (0.9, 1.2),\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    validation_split = 0.15,\n",
    "    preprocessing_function = random_input,\n",
    ")\n",
    "\n",
    "valid_datagen=ImageDataGenerator(rescale=1./255,validation_split=0.15)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=traindf,\n",
    "    directory=train_path,\n",
    "    x_col=\"id\",\n",
    "    y_col=classes,\n",
    "    subset=\"training\",\n",
    "    batch_size=70,\n",
    "    seed=123,\n",
    "    shuffle=False,\n",
    "    class_mode=\"raw\",\n",
    "    target_size=(224,224))\n",
    "\n",
    "\n",
    "STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_dataframe(\n",
    "    dataframe=traindf,\n",
    "    directory=train_path,\n",
    "    x_col=\"id\",\n",
    "    y_col=classes,\n",
    "    subset=\"validation\",\n",
    "    batch_size=70,\n",
    "    seed=123,\n",
    "    shuffle=False,\n",
    "    class_mode=\"raw\",\n",
    "    target_size=(224, 224))\n",
    "\n",
    "STEP_SIZE_VALID = valid_generator.n // valid_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lqxrTwSobQ3-"
   },
   "outputs": [],
   "source": [
    "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
    "train_generator.mean=train_generator\n",
    "valid_generator.mean=valid_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "082SRgPvbU5z"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model,load_model\n",
    "from keras.applications.resnet_v2 import ResNet50V2\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.layers import Add,Input,Dense,Dropout,BatchNormalization,Activation,Flatten,Conv2D,MaxPooling2D,ZeroPadding2D,Lambda,AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import SGD, RMSprop, Adam, Adagrad\n",
    "from keras.initializers import glorot_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "colab_type": "code",
    "id": "nzNCpxgPbXPz",
    "outputId": "6659eba8-7ebe-4efe-d2ff-d6567f1b578a"
   },
   "outputs": [],
   "source": [
    "!pip install efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 398
    },
    "colab_type": "code",
    "id": "mueTu382bY5i",
    "outputId": "66e1122a-89f3-4060-bba8-cfaebbe68982"
   },
   "outputs": [],
   "source": [
    "import efficientnet.keras as efn \n",
    "import keras.backend as backend\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "        return backend.sqrt(backend.mean(backend.square(y_pred - y_true))) \n",
    "def build_model():\n",
    "    eff1 = efn.EfficientNetB0(weights='imagenet',include_top=False,input_shape=(224,224,3))\n",
    "    model = Sequential()\n",
    "    model.add(eff1)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(37, activation='sigmoid'))\n",
    "    return model\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kn3THr9FFFHo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MPR4pZQiE2XA"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=rmse,\n",
    "                  optimizer=Adam(lr=1.5e-4), \n",
    "                  metrics=[rmse, 'acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MjNHEpwxbbmK"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "\n",
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.rmse = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.rmse.append(logs.get('rmse'))\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', patience=10, verbose=1, mode='auto')\n",
    "\n",
    "history = LossHistory()\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath='/content/drive/My Drive/results/weights_efficientnetB0_FC16.hdf5', verbose=2, save_best_only=True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=4,)\n",
    "\n",
    "csv_logger = CSVLogger('/content/drive/My Drive/results/history/training_efficientnetB2_FC16.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Y2YKQn87bflz",
    "outputId": "7fd32550-f553-477c-d552-21104e662590"
   },
   "outputs": [],
   "source": [
    "hist = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=STEP_SIZE_VALID,\n",
    "    epochs=50,\n",
    "    callbacks=[history, checkpointer, reduce_lr, early_stopping, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w1VxT6VFb5br"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of EfficientNetB0Regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
