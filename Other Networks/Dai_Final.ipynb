{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eCKPRidoFXV9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import PIL\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing.image import img_to_array,ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "hECXYeA-FbT0",
    "outputId": "17d15f01-6bc8-4f13-89ba-54d15ef50ef3"
   },
   "outputs": [],
   "source": [
    "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
    "TPU_ADDRESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VJp0_E6-FkY9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "!unzip -q '/content/drive/My Drive/Classification/GalaxyClassification.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4L1jp-oQFrEf"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Flatten, Dense, Add, Lambda, Input, Reshape, Conv2D, MaxPooling2D, BatchNormalization, Activation, ZeroPadding2D, GlobalMaxPooling2D, Dropout, AveragePooling2D\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HFwl3Fz3FtIz"
   },
   "outputs": [],
   "source": [
    "classes = [\"class 0\",\"class 1\",\"class 2\",\"class 3\",\"class 4\", \"class 5\",\"class 6\"]\n",
    "\n",
    "def append_ext(fn):\n",
    "    return fn + \".jpg\"\n",
    "\n",
    "\n",
    "traindf = pd.read_csv(\"/content/datasets/train.csv\")\n",
    "traindf[\"id\"] = traindf['GalaxyID'].astype(str).apply(append_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jvD7xLFmFvMD"
   },
   "outputs": [],
   "source": [
    "train_path = \"/content/images/train_pool/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l93YUBUFFw_r"
   },
   "outputs": [],
   "source": [
    "def random_input(img):\n",
    "    shape = img.shape[:2]\n",
    "    left = int(shape[0]/4)\n",
    "    top = int(shape[1]/4)\n",
    "    img = img[left:left*3,top:top*3,:]\n",
    "    image = cv2.resize(img, shape, interpolation = cv2.INTER_CUBIC)\n",
    "    image = img_to_array(image)\n",
    "    return image\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    rotation_range=140,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    brightness_range = (0.9, 2),\n",
    "    samplewise_std_normalization=False,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    validation_split = 0.15,\n",
    "    preprocessing_function = random_input,\n",
    ")\n",
    "\n",
    "valid_datagen=ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.15,\n",
    "    preprocessing_function = random_input,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "ns6w-C8yFyvF",
    "outputId": "32e36ad0-ade8-46d1-f83b-a782c9529413"
   },
   "outputs": [],
   "source": [
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=traindf,\n",
    "    directory=train_path,\n",
    "    x_col=\"id\",\n",
    "    y_col=classes,\n",
    "    subset=\"training\",\n",
    "    batch_size=32,\n",
    "    seed=123,\n",
    "    shuffle=False,\n",
    "    class_mode=\"raw\",\n",
    "    target_size=(224,224))\n",
    "\n",
    "\n",
    "STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_dataframe(\n",
    "    dataframe=traindf,\n",
    "    directory=train_path,\n",
    "    x_col=\"id\",\n",
    "    y_col=classes,\n",
    "    subset=\"validation\",\n",
    "    batch_size=32,\n",
    "    seed=123,\n",
    "    shuffle=False,\n",
    "    class_mode=\"raw\",\n",
    "    target_size=(224, 224))\n",
    "\n",
    "STEP_SIZE_VALID = valid_generator.n // valid_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5_7HQH5vF9PE"
   },
   "outputs": [],
   "source": [
    "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
    "train_generator.mean=train_generator\n",
    "valid_generator.mean=valid_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SCHxjBoDF_Hk"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model,load_model\n",
    "from keras.applications.resnet import ResNet152\n",
    "from keras.applications.resnet_v2 import ResNet50V2\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Flatten, Dense, Add, Multiply, Lambda, Input, Reshape, Conv2D, DepthwiseConv2D, MaxPooling2D, BatchNormalization, Activation, ZeroPadding2D, GlobalAveragePooling2D, GlobalMaxPooling2D, Dropout, AveragePooling2D\n",
    "from keras.optimizers import SGD, RMSprop, Adam, Adagrad\n",
    "from keras.initializers import glorot_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 722
    },
    "colab_type": "code",
    "id": "XWK575lPGArY",
    "outputId": "7b556b7e-0630-40e2-9355-b5b491db7f56"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pXSRkmtrJHz9"
   },
   "outputs": [],
   "source": [
    "  def Convolution_Block(X, filters_m, filters_n, block, k=2, downsampling = True):\n",
    "    '''\n",
    "        Arguments:\n",
    "        X - Input tensor to the block\n",
    "        filters_m - Filters to provide to the first two conv layers of each residual unit\n",
    "        filters_n - last layer filters\n",
    "        block - number\n",
    "        k =  widening factor\n",
    "    '''\n",
    "    strides = 1\n",
    "    if downsampling:\n",
    "        strides = 2\n",
    "    else:\n",
    "        strides = 1\n",
    "    #BLOCK 1\n",
    "    #First residual block\n",
    "    X_shortcut = X\n",
    "    X = BatchNormalization(name='conv'+str(block)+'_1_conv1_bn')(X)\n",
    "    X = Activation('relu', name='conv'+str(block)+'_1_conv1_relu')(X)\n",
    "    X = Conv2D(filters = filters_m*k, kernel_size = (1,1), name = 'conv1'+str(block)+'_1_conv1', padding = 'same')(X)\n",
    "\n",
    "    X = BatchNormalization(name='conv'+str(block)+'_1_conv2_bn')(X)\n",
    "    X = Activation('relu', name='conv1'+str(block)+'_1_conv2_relu')(X)\n",
    "    X = Conv2D(filters = filters_m*k, kernel_size = (3,3), name = 'conv'+str(block)+'_1_conv2', padding='same')(X)\n",
    "    \n",
    "    X = Dropout(rate=0.8, name = 'conv'+str(block)+'_1_conv3_dropout')(X)\n",
    "    X = BatchNormalization(name='conv'+str(block)+'_1_conv3_bn')(X)\n",
    "    X = Activation('relu', name='conv'+str(block)+'_1_conv3_relu')(X)\n",
    "    X = Conv2D(filters = filters_n*k, kernel_size = (1,1), name = 'conv'+str(block)+'_1_conv3', padding='same')(X)\n",
    "\n",
    "\n",
    "    X_shortcut = Conv2D(filters = filters_n*k, kernel_size = (1,1), name = 'conv'+str(block)+'_01_conv', padding='same')(X_shortcut)\n",
    "\n",
    "    X = Add()([X, X_shortcut])\n",
    "    #Second residual block\n",
    "\n",
    "    X_shortcut = X\n",
    "    X = BatchNormalization(name='conv'+str(block)+'_2_conv1_bn')(X)\n",
    "    X = Activation('relu', name='conv'+str(block)+'_2_conv1_relu')(X)\n",
    "    X = Conv2D(filters = filters_m*k, kernel_size = (1,1), name = 'conv1'+str(block)+'_2_conv1', padding='same')(X)\n",
    "\n",
    "    X = BatchNormalization(name='conv'+str(block)+'_2_conv2_bn')(X)\n",
    "    X = Activation('relu', name='conv1'+str(block)+'_2_conv2_relu')(X)\n",
    "    X = Conv2D(filters = filters_m*k, kernel_size = (3,3), name = 'conv'+str(block)+'_2_conv2', padding='same')(X)\n",
    "\n",
    "    X = BatchNormalization(name='conv'+str(block)+'_2_conv3_bn')(X)\n",
    "    X = Activation('relu', name='conv'+str(block)+'_2_conv3_relu')(X)\n",
    "    X = Conv2D(filters = filters_n*k, kernel_size = (1,1), strides =strides, name = 'conv'+str(block)+'_2_conv3', padding='same')(X)\n",
    "\n",
    "\n",
    "    if downsampling:\n",
    "        X_shortcut = Conv2D(filters = filters_n*k, kernel_size = (1,1), strides=2, name = 'conv'+str(block)+'_02_conv')(X_shortcut)\n",
    "        #X_shortcut = MaxPooling2D(pool_size = 2, strides = 2, name = 'conv'+str(block)+'_02_pool')(X_shortcut)\n",
    "    else:\n",
    "        #X_shortcut = ZeroPadding2D(padding = (1,1), name = 'conv'+str(block)+'_02_conv3_pad')(X_shortcut)\n",
    "        X_shortcut = Conv2D(filters = filters_n*k, kernel_size = (1,1), name = 'conv'+str(block)+'_02_conv', padding='same')(X_shortcut)\n",
    "\n",
    "    X = Add(name = 'block'+str(block)+'output')([X, X_shortcut])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ju1iD6Y_GC7R"
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "  def build_model(input_shape = (224,224,3)):\n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    X = Conv2D(filters = 64, kernel_size = (6,6), padding='same')(X_input)\n",
    "    X = MaxPooling2D(pool_size = (2,2), strides = (2,2))(X)\n",
    "\n",
    "    X = Convolution_Block(X, filters_m=64, filters_n=256, block=1, k=2, downsampling=True)\n",
    "    X = Convolution_Block(X, filters_m=128, filters_n=512, block=2, k=2, downsampling=True)\n",
    "    X = Convolution_Block(X, filters_m=256, filters_n=1024, block=3, k=2, downsampling=True)\n",
    "    X = Convolution_Block(X, filters_m=512, filters_n=2048, block=4, k=2, downsampling=False)\n",
    "    \n",
    "\n",
    "    X = AveragePooling2D(pool_size = (4,4))(X)\n",
    "\n",
    "    X = Flatten(name = 'flatten')(X)\n",
    "    X = Dense(7, activation = 'softmax', name = 'Output')(X)\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-7mbdz7Q_U1f",
    "outputId": "f7702772-7e27-4774-a5b3-7e7867c139b8"
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "  model = build_model(input_shape=(224,224,3))\n",
    "  model.summary()\n",
    "  opt = Adam(lr=1.1e-3)\n",
    "  model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt, \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gHYJD1ZvRJk6"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "\n",
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', patience=10, verbose=1, mode='auto')\n",
    "\n",
    "history = LossHistory()\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath='/content/drive/My Drive/Classification/results/weights_DaiNet.hdf5', verbose=2, save_best_only=True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=4,)\n",
    "\n",
    "csv_logger = CSVLogger('/content/drive/My Drive/Classification/results/training_DaiNet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Hm9gd4lz_NLn",
    "outputId": "5b1fea0e-6ff3-40da-b9ee-814e0c747eee"
   },
   "outputs": [],
   "source": [
    "hist = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=STEP_SIZE_VALID,\n",
    "    epochs=30,\n",
    "    callbacks=[history, checkpointer, reduce_lr, early_stopping, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5TfNLCbm_Sov"
   },
   "outputs": [],
   "source": [
    "model = load_model('/content/drive/My Drive/Classification/results/weights_DaiNet.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "o-VZZL7RvtK6",
    "outputId": "11292a67-3e5a-4948-ea6b-39823b7f6ed5"
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    preprocessing_function = random_input,\n",
    "    )\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    \"/content/images/test\",\n",
    "    class_mode=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    target_size=(224, 224),\n",
    "    seed=123,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "V3aH6h46v-7P",
    "outputId": "41b2f64b-56e9-4d99-dd51-be144cc0ab66"
   },
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "\n",
    "Y_pred = model.predict_generator(\n",
    "    test_generator,\n",
    "    steps=test_generator.n / test_generator.batch_size,\n",
    "    verbose=1)\n",
    "\n",
    "y_pred = np.argmax(Y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NF2qGcHPwBDx"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "cf=confusion_matrix(test_generator.classes, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "Hbd8dw8xAUN8",
    "outputId": "97b0dca8-3e30-4ccd-de70-ed6c656ea3ea"
   },
   "outputs": [],
   "source": [
    "print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "IHcBM_GFAV60",
    "outputId": "dbbc62a5-649b-4f92-f774-c1dcd2078105"
   },
   "outputs": [],
   "source": [
    "classification_report = classification_report(test_generator.classes, y_pred, target_names=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "TChJkMABAXnH",
    "outputId": "4cfb7f0d-986a-4445-cfaa-ee8f30efee35"
   },
   "outputs": [],
   "source": [
    "print(classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2BbQGghmAZ5q"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "Dai_Final",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
